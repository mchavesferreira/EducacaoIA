# üß† Adapta√ß√µes e Estrat√©gias de Uso de LLMs

## üìñ Introdu√ß√£o: O que √© uma LLM?

<img width="610" height="384" alt="Captura de tela 2025-11-25 224210" src="https://github.com/user-attachments/assets/9d0470cc-bedc-4f12-843b-fa2bcbf2cca6" />

<img width="587" height="364" alt="Captura de tela 2025-11-25 224219" src="https://github.com/user-attachments/assets/7ae06e22-7f24-4616-87f2-fa45d535d640" />

As **Large Language Models (LLMs)** s√£o modelos de linguagem baseados em aprendizado profundo capazes de **prever a pr√≥xima palavra** de uma sequ√™ncia de texto.  
Formalmente, elas calculam a **probabilidade condicional** de uma sequ√™ncia de tokens:

\[
P(w_1, w_2, ..., w_n) = \prod_i P(w_i | w_1, ..., w_{i-1})
\]

Isso significa que, dado o contexto anterior, o modelo tenta prever o token seguinte.

### üß© Exemplo:
Senten√ßa:  
> ‚ÄúO gato est√° entrando no ‚Ä¶‚Äù

Poss√≠veis previs√µes:  
- quarto ‚úÖ  
- cozinha ‚ùå  
- papagaio ‚ùå  

A LLM atribui maior probabilidade √† palavra **‚Äúquarto‚Äù**, pois o contexto torna essa previs√£o mais plaus√≠vel.

---

## üï∞Ô∏è Hist√≥rico da Evolu√ß√£o dos Modelos de Linguagem

### üîπ Recurrent Neural Networks (RNNs)
As RNNs processam sequ√™ncias passo a passo, armazenando informa√ß√µes anteriores em um **estado oculto (h)**.  
Por√©m, sofrem com o **problema da mem√≥ria de longo prazo**, pois esquecem informa√ß√µes antigas em senten√ßas longas.

- **Vantagem:** Boa para s√©ries temporais curtas.  
- **Limita√ß√£o:** C√°lculo sequencial ‚Äî n√£o aproveita paralelismo de GPU.

### üîπ Long Short-Term Memory (LSTM) e GRU
Surgiram para mitigar a perda de mem√≥ria, mas ainda mantinham depend√™ncia sequencial.

---

## ‚ö° A Revolu√ß√£o dos Transformers (2017)

O paper **‚ÄúAttention is All You Need‚Äù (Vaswani et al., Google, 2017)** substituiu a recorr√™ncia pela **aten√ß√£o**.

### üéØ Conceito de Aten√ß√£o:
A rede aprende **aonde olhar** na senten√ßa para prever a pr√≥xima palavra.  
Cada token se relaciona com todos os outros simultaneamente ‚Äî o que permite **processamento paralelo** e **mem√≥ria de longo prazo**.

### üß† Self-Attention:
Cada palavra se relaciona consigo mesma e com as demais, aprendendo **rela√ß√µes internas** (gramaticais e sem√¢nticas).

### üßÆ Multi-Head Attention:
O modelo aprende m√∫ltiplas proje√ß√µes (‚Äúcabe√ßas‚Äù), cada uma capturando diferentes tipos de rela√ß√£o ‚Äî sem√¢ntica, sint√°tica, l√©xica etc.

---

## üöÄ Do Transformer ao GPT e BERT

| Modelo | Ano | Aplica√ß√£o | Caracter√≠stica |
|--------|-----|------------|----------------|
| **GPT (OpenAI)** | 2018 | Gera√ß√£o de texto | Treinamento unidirecional |
| **BERT (Google)** | 2019 | An√°lise de texto | Treinamento bidirecional |

Ambos introduziram o **pr√©-treinamento**: aprender a linguagem antes de resolver tarefas espec√≠ficas.

---

## üí° O Salto das LLMs: ChatGPT e Modelos Gigantes

A evolu√ß√£o de **GPT-3 e GPT-4** introduziu bilh√µes de par√¢metros e **Feedback Humano (RLHF)**, tornando as respostas mais ‚Äúhumanas‚Äù e contextuais.

> O grande diferencial do ChatGPT n√£o foi o tamanho, mas o **feedback humano** e a interface de convers√ß√£o.

---

## üßÆ Aplica√ß√µes Pr√°ticas de LLMs

### üóÇÔ∏è Exemplo: OCR Tradicional vs. LLM

**Antes:**  
1. Coleta de dados  
2. Rotula√ß√£o manual  
3. Treinamento e avalia√ß√£o

**Agora com LLM:**  
Uma imagem de uma placa de motor pode ser enviada diretamente para a LLM multimodal, que extrai a pot√™ncia em segundos ‚Äî sem treinamento adicional.

---

## üé® Prompt Engineering

### üß† Defini√ß√£o:
Arte de estruturar **instru√ß√µes (prompts)** para obter respostas precisas, sem alterar os par√¢metros do modelo.

### üìã Exemplo ruim:
> ‚ÄúResuma este texto.‚Äù

### üìã Exemplo bom:
> ‚ÄúResuma o texto abaixo em 3 frases, destacando os principais argumentos jur√≠dicos em linguagem simples.‚Äù

### üîß Boas Pr√°ticas:
- Seja **espec√≠fico** sobre o formato da resposta (JSON, tabela, texto).  
- **Defina pap√©is:** ‚ÄúVoc√™ √© um professor de eletr√¥nica...‚Äù  
- Use **exemplos** (few-shot).  
- Limite o tamanho com **max tokens**.  

---

## üî• Par√¢metros Importantes na API

| Par√¢metro | Descri√ß√£o | Recomenda√ß√µes |
|------------|-------------|---------------|
| **Temperature** | Controla criatividade (0 = previs√≠vel, 1 = criativo) | 0 para c√°lculos, 1 para ideias |
| **Top-K / Top-P** | Limita as palavras candidatas | Reduz alucina√ß√µes e lat√™ncia |
| **Max Tokens** | Limite de sa√≠da | Evita custos e respostas longas |

---



## üß© T√©cnicas de Prompt Engineering

### 1. **General Prompting /Zero Shot**
Pedir a tarefa diretamente, sem exemplos.  
> ‚ÄúClassifique este texto como positivo, negativo ou neutro.‚Äù


### 2. **Single /Few Shot**
Fornece exemplos no prompt entrada/saida (ou apenas um).  
> Entrada: ‚ÄúAdorei o atendimento.‚Äù ‚Üí Sa√≠da: ‚ÄúPositivo‚Äù

### 3. **Step-Back Prompting**
Criar um contexto intermedi√°rio.  
> ‚ÄúListe os tipos de jogos FPS antes de propor um novo enredo.‚Äù


### 4. **Chain-of-Thought (CoT)**
Pedir que o modelo **pense passo a passo**.  
> ‚ÄúExplique o racioc√≠nio antes de dar a resposta final.‚Äù



### 5. **Pipeline Prompts**
Dividir uma tarefa grande em **etapas menores** ‚Äî ideal para produ√ß√£o.



## üîç Recupera√ß√£o de Contexto: RAG (Retrieval Augmented Generation)

### üß© Conceito:
Combina **busca sem√¢ntica** + **gera√ß√£o textual**.

### ‚öôÔ∏è Etapas:
1. **Carregar dados (Data Loading)**  
   - Extrair texto de PDFs, imagens (OCR), v√≠deos (transcri√ß√£o).  
2. **Chunking**  
   - Dividir texto em partes menores (ex: 1000 tokens).  
3. **Cria√ß√£o de Embeddings**  
   - Mapear cada trecho para um vetor num√©rico.  
4. **Armazenamento em Banco Vetorial**  
   - Ex: ChromaDB, PostgreSQL + PGVector, Weaviate.  
5. **Busca por Similaridade (Cosine Distance)**  
   - Localiza os trechos mais pr√≥ximos da pergunta.  
6. **Gera√ß√£o com Contexto**  
   - Envia os trechos relevantes para a LLM responder com precis√£o.

### üßÆ Exemplo:
Pergunta: ‚ÄúQual a pot√™ncia do motor WEG modelo X?‚Äù  
‚Üí Busca sem√¢ntica encontra o documento t√©cnico correto  
‚Üí LLM gera resposta citando a fonte.

---

## üî∫ Fine-Tuning (Ajuste Fino)

### üéØ Defini√ß√£o:
Re-treinar parte de um modelo j√° existente para uma tarefa espec√≠fica.

- Requer **dataset rotulado**  
- √â **caro e lento**  
- Pode fazer o modelo ‚Äúesquecer‚Äù o conhecimento anterior (**catastrophic forgetting**)

### üí∞ Exemplo de Custo:
Treinamento de um modelo DeepSeek ‚Üí 2 meses / 5 milh√µes USD.

### ‚öôÔ∏è T√©cnicas Eficientes:
- **PEFT (Parameter-Efficient Fine-Tuning)**  
  Treina apenas parte do modelo (√∫ltimas camadas).  
- **LoRA (Low-Rank Adaptation)**  
  Adiciona pequenas matrizes ŒîW para adaptar o comportamento, sem alterar os pesos originais.

> Vantagem: m√∫ltiplos LoRAs podem coexistir sobre o mesmo modelo base.


---

## ‚öóÔ∏è Outras Estrat√©gias Avan√ßadas

| T√©cnica | Fun√ß√£o | Observa√ß√£o |
|---------|--------|-------------|
| **Quantiza√ß√£o** | Reduz precis√£o dos pesos (ex: FP32 ‚Üí INT8) | Acelera infer√™ncia |
| **Distila√ß√£o** | Treinar modelo menor a partir de um modelo grande | Economiza GPU |
| **Mixture of Experts (MoE)** | Divide o modelo em especialistas ativados sob demanda | Reduz custo de infer√™ncia |
| **GraphRAG** | Conecta documentos por rela√ß√µes sem√¢nticas (ontologia) | Ideal para bases corporativas |
| **Re-Ranker** | Reordena resultados da busca pelo melhor contexto | Melhora precis√£o no RAG |


- Quantiza√ß√£o

<img width="1080" height="1115" alt="quantizacao" src="https://github.com/user-attachments/assets/c800c8f6-eaa1-4ba0-a83d-3155c94bc4c1" />

- Destila√ß√£o
<img width="799" height="402" alt="destila√ß√£o" src="https://github.com/user-attachments/assets/2fd1aefe-ae8f-4334-91eb-c5c96aaf3381" />


- Mixture of Experts (MoE)
<img width="535" height="444" alt="moe" src="https://github.com/user-attachments/assets/508fada0-8473-4444-93aa-cbc3587b908d" />



- GraphRAG/
 
![graph_rag](https://github.com/user-attachments/assets/c41c8b5b-ce4c-4f39-aa89-e49d0c958721)

- Re-Ranker
<img width="1185" height="458" alt="Reranking_after_initial_vector_search" src="https://github.com/user-attachments/assets/00b44870-8eb3-4476-913f-94decf1e325c" />

- 
---

## ü¶Ø Agentes e MCP (Model Context Protocol)

### ü§ñ Agentes
S√£o LLMs capazes de **tomar decis√µes e executar a√ß√µes** (como chamar APIs ou outros agentes).

### üîó MCP
Protocolo que permite a um agente **descobrir automaticamente** quais rotas e fun√ß√µes externas est√£o dispon√≠veis.

---

## üè¢ LLMs no Contexto Industrial

Segundo a experi√™ncia da **Tractian**, o uso ideal ocorre em:
- Dados **n√£o estruturados** (documentos, relat√≥rios, √°udios, OCRs).
- Processos de **an√°lise preliminar e prototipagem r√°pida**.
- Suporte a **engenheiros de manuten√ß√£o** e **diagn√≥stico textual**.

> Para an√°lise espectral e sinais de sensores, m√©todos tradicionais (estat√≠stica + ML cl√°ssico) ainda s√£o mais adequados.

---

## üí¨ Boas Pr√°ticas Gerais

1. **Comece simples** ‚Äî otimize depois.  
2. **Documente** o racioc√≠nio de cada prompt.  
3. **Prefira modularidade** ‚Äî divida tarefas complexas.  
4. **Use RAG antes de Fine-Tuning.**  
5. **Controle custos** ‚Äî tokens = tempo + dinheiro.  
6. **Verifique fontes** ‚Äî LLMs n√£o garantem veracidade.  
7. **Evite acoplamento a um banco ou API.**

---

## üìö Refer√™ncias Recomendadas

- Vaswani et al. (2017) ‚Äì *Attention Is All You Need*  
- Devlin et al. (2018) ‚Äì *BERT: Pre-training of Deep Bidirectional Transformers*  
- Brown et al. (2020) ‚Äì *Language Models are Few-Shot Learners (GPT-3)*  
- DeepSeek Team (2023) ‚Äì *Open Source Efficient Training Techniques*  
- Google (2024) ‚Äì *Prompt Design Guide for Gemini*  
- Hugging Face Docs ‚Äì *PEFT & LoRA Implementations*

---

## üßí‚Äç‚öñÔ∏è Conclus√£o

Os **modelos de linguagem** revolucionaram o aprendizado de m√°quina ao eliminar boa parte da barreira de dados e permitir que tarefas complexas fossem resolvidas **com simples prompts**.

> O futuro est√° na combina√ß√£o: **LLMs + RAG + Fine-Tuning seletivo + Engenharia de Prompts.**

